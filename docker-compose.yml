x-loki-defaults: &loki_defaults
    user: root
    image: grafana/loki:${LOKI_VERSION?Variable not set}
    depends_on:
      - minio
    networks:
      default:
        aliases:
          - loki
      prometheus:
    entrypoint:
      - sh
      - -euc
      - |
        mkdir -p /var/loki
        export INSTANCE_ADDR=$$(hostname -i | grep -E -o "10\.0\.5\.[0-9]{1,3}")
        cat <<EOF > /etc/loki/config.yml
        target: $${TARGET:-all}
        auth_enabled: false
        server:
          http_listen_port: 3100
          grpc_listen_port: 9095
          # log_level: debug
          # log_format: logfmt
          http_server_read_timeout: 60s
          http_server_write_timeout: 60s
          grpc_server_max_recv_msg_size: 67108864
          grpc_server_max_send_msg_size: 67108864
        distributor:
          ring:
            instance_addr: $${INSTANCE_ADDR}
        querier:
          max_concurrent: 20
        query_scheduler:
          max_outstanding_requests_per_tenant: 2048
          grpc_client_config:
            max_send_msg_size: 67108864
            max_recv_msg_size: 67108864
          scheduler_ring:
            instance_addr: $${INSTANCE_ADDR}
        frontend:
          max_outstanding_per_tenant: 2048
          compress_responses: true
          log_queries_longer_than: 20s
        # TODO: chunk_cache
        query_range:
          align_queries_with_step: true
          # parallelise_shardable_queries: false
          cache_results: true
          results_cache:
            cache:
              default_validity: 12h
              memcached_client:
                addresses: dns+general-memcached:11211
        ruler:
          storage:
            type: s3
            s3:
              bucketnames: ruler
          ring:
            instance_addr: $${INSTANCE_ADDR}
        frontend_worker:
          grpc_client_config:
            max_send_msg_size: 67108864
            max_recv_msg_size: 67108864
        ingester_client:
          grpc_client_config:
            max_send_msg_size: 67108864
            max_recv_msg_size: 67108864
        ingester:
          autoforget_unhealthy: true
          lifecycler:
            address: $${INSTANCE_ADDR}
        memberlist:
          abort_if_cluster_join_fails: false
          advertise_addr: $${INSTANCE_ADDR}
          join_members:
          - loki
        storage_config:
          hedging:
            at: 250ms
            max_per_second: 20
            up_to: 3
        schema_config:
          configs:
          - from: "2022-01-11"
            index:
              period: 24h
              prefix: loki_index_
            object_store: s3
            schema: v12 # v11
            store: boltdb-shipper
        compactor:
          retention_enabled: true
          compactor_ring:
            instance_addr: $${INSTANCE_ADDR}
        limits_config:
          retention_period: ${RETENTION?Variable not set}
          max_cache_freshness_per_query: 10m
          enforce_metric_name: false
          ingestion_rate_mb: 25
          ingestion_burst_size_mb: 50
          # split_queries_by_interval: 0
          per_stream_rate_limit: 10MB
          per_stream_rate_limit_burst: 30MB
        common:
          path_prefix: /var/loki
          storage:
            s3:
              s3forcepathstyle: ${S3_FORCE_PATH_STYLE?Variable not set}
              bucketnames: chunks
              endpoint: ${S3_ENDPOINT?Variable not set}
              region: ${S3_REGION?Variable not set}
              access_key_id: ${S3_ACCESS_KEY?Variable not set}
              secret_access_key: ${S3_SECRET_KEY?Variable not set}
              insecure: ${S3_INSECURE?Variable not set}
          compactor_address: loki-backend:3100
          compactor_grpc_address: loki-backend:9095
          replication_factor: 3
        index_gateway:
          mode: ring
        EOF
        exec loki -config.file=/etc/loki/config.yml -legacy-read-mode=false
    deploy:
      replicas: 3
      labels:
        - prometheus.port=3100
      resources:
        limits:
          cpus: '1.0'
          memory: 1G
        reservations:
          cpus: '0.25'
          memory: 250M

x-tempo-defaults: &tempo_defaults
  user: root
  image: grafana/tempo:${TEMPO_VERSION?Variable not set}
  depends_on:
    - minio
  networks:
    default:
      aliases:
        - tempo
    prometheus:
  entrypoint:
    - sh
    - -euc
    - |
      mkdir -p /var/tempo
      export INSTANCE_ADDR=$$(hostname -i | grep -E -o "10\.0\.5\.[0-9]{1,3}")
      cat <<EOF > /var/tempo/config.yml
      target: $${TARGET:-all}
      server:
        http_listen_port: 3100
        grpc_listen_port: 9095
        # log_level: debug
        # log_format: logfmt
        http_server_read_timeout: 60s
        http_server_write_timeout: 60s
        grpc_server_max_recv_msg_size: 134217728
        grpc_server_max_send_msg_size: 134217728
      distributor:
        receivers:
          otlp:
            protocols:
              grpc:
              http:
        ring:
          instance_addr: $${INSTANCE_ADDR}
          kvstore:
            store: memberlist
      compactor:
        compaction:
          block_retention: ${RETENTION?Variable not set}
        ring:
          instance_addr: $${INSTANCE_ADDR}
          kvstore:
            store: memberlist
      ingester:
        lifecycler:
          address: $${INSTANCE_ADDR}
          ring:
            kvstore:
              store: memberlist
            replication_factor: 3
          tokens_file_path: /var/tempo/tokens.json
      querier:
        frontend_worker:
          frontend_address: tempo-query-frontend:9095
      # query_frontend:
      #   search:
      #     max_duration: 0 # 12h0m0s
      memberlist:
        abort_if_cluster_join_fails: false
        advertise_addr: $${INSTANCE_ADDR}
        join_members:
        - tempo
      metrics_generator:
        registry:
          external_labels:
            source: tempo
        ring:
          instance_addr: $${INSTANCE_ADDR}
          kvstore:
            store: memberlist
        storage:
          path: /var/tempo/wal
          remote_write:
            - url: http://prometheus:9090/api/v1/write
              send_exemplars: true
      multitenancy_enabled: false
      overrides:
        metrics_generator_processors:
          - service-graphs
          - span-metrics
        # per_tenant_override_config: /conf/overrides.yaml
      storage:
        trace:
          backend: s3
          cache: memcached
          local:
            path: /var/tempo/traces
          s3:
            bucket: tempo
            endpoint: ${S3_ENDPOINT?Variable not set}
            region: ${S3_REGION?Variable not set}
            access_key: ${S3_ACCESS_KEY?Variable not set}
            secret_key: ${S3_SECRET_KEY?Variable not set}
            insecure: ${S3_INSECURE?Variable not set}
            forcepathstyle: ${S3_FORCE_PATH_STYLE?Variable not set}
          memcached:
            addresses: dns+general-memcached:11211
          wal:
            path: /var/tempo/wal
      EOF
      exec /tempo -config.file=/var/tempo/config.yml
  deploy:
    labels:
      - prometheus.port=3100
    resources:
      limits:
        cpus: '0.5'
        memory: 1G
      reservations:
        cpus: '0.1'
        memory: 250M

version: '3.8'

services:
  prometheus:
    image: ${DOCKER_PROMETHEUS_IMAGE?Variable not set}:v${PROMETHEUS_VERSION?Variable not set}
    build:
      context: ./prometheus
      args:
        PROMETHEUS_VERSION: ${PROMETHEUS_VERSION?Variable not set}
    networks:
      default:
      traefik-public:
      prometheus:
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock:ro
      - prometheus-data:/prometheus
    command:
      - --config.file=/etc/prometheus/prometheus.yml
      - --storage.tsdb.path=/prometheus
      - --storage.tsdb.retention.time=${RETENTION?Variable not set}
      - --web.enable-remote-write-receiver
      - --web.enable-admin-api
      - --enable-feature=exemplar-storage
    deploy:
      placement:
        constraints:
          - node.role == manager
          - node.labels.${STACK_NAME?Variable not set}.prometheus-data == true
      resources:
        limits:
          memory: 2048M
        reservations:
          memory: 256M
      labels:
        - traefik.enable=true
        - traefik.docker.network=${TRAEFIK_PUBLIC_NETWORK?Variable not set}
        - traefik.constraint-label=${TRAEFIK_PUBLIC_TAG?Variable not set}
        - traefik.http.middlewares.${STACK_NAME?Variable not set}-prometheus-auth.basicauth.users=${USERNAME?Variable not set}:${HASHED_PASSWORD?Variable not set}
        - traefik.http.routers.${STACK_NAME?Variable not set}-prometheus-http.rule=Host(`prometheus.${DOMAIN?Variable not set}`)
        - traefik.http.routers.${STACK_NAME?Variable not set}-prometheus-http.entrypoints=http
        - traefik.http.routers.${STACK_NAME?Variable not set}-prometheus-http.middlewares=https-redirect,common-security-headers
        - traefik.http.routers.${STACK_NAME?Variable not set}-prometheus-https.rule=Host(`prometheus.${DOMAIN?Variable not set}`)
        - traefik.http.routers.${STACK_NAME?Variable not set}-prometheus-https.entrypoints=https
        - traefik.http.routers.${STACK_NAME?Variable not set}-prometheus-https.tls=true
        - traefik.http.routers.${STACK_NAME?Variable not set}-prometheus-https.tls.certresolver=le
        - traefik.http.routers.${STACK_NAME?Variable not set}-prometheus-https.middlewares=common-security-headers,${STACK_NAME?Variable not set}-prometheus-auth
        - traefik.http.services.${STACK_NAME?Variable not set}-prometheus.loadbalancer.server.port=9090
        - prometheus.port=9090

  cadvisor:
    image: gcr.io/cadvisor/cadvisor:v${CADVISOR_VERSION?Variable not set}
    networks:
      - ${PROMETHEUS_NETWORK?Variable not set}
    command: -docker_only
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock:ro
      - /:/rootfs:ro
      - /var/run:/var/run
      - /sys:/sys:ro
      - /var/lib/docker/:/var/lib/docker:ro
    deploy:
      mode: global
      resources:
        limits:
          memory: 512M
        reservations:
          memory: 256M
      labels:
        - prometheus.port=8080

  node-exporter:
    image: prom/node-exporter:v${NODE_EXPORTER_VERSION?Variable not set}
    networks:
      prometheus:
    command: --path.rootfs=/host
    volumes:
      - /:/host:ro,rslave
    deploy:
      mode: global
      resources:
        limits:
          memory: 256M
        reservations:
          memory: 128M
      labels:
        - prometheus.port=9100

  minio:
    image: minio/minio:${MINIO_VERSION?Variable not set}
    networks:
      default:
      traefik-public:
      prometheus:
    entrypoint:
      - sh
      - -euc
      - |
        mkdir -p /data/chunks /data/ruler /data/admin /data/tempo && \
        exec minio server /data --console-address ":9001"
    environment:
      - MINIO_ACCESS_KEY=${S3_ACCESS_KEY?Variable not set}
      - MINIO_SECRET_KEY=${S3_SECRET_KEY?Variable not set}
      - MINIO_BROWSER_REDIRECT_URL=https://minio-console.${DOMAIN?Variable not set}
      - MINIO_SERVER_URL=https://minio.${DOMAIN?Variable not set}
      - MINIO_PROMETHEUS_AUTH_TYPE=public
      # - MINIO_UPDATE=off
    volumes:
      - minio-data:/data
    healthcheck:
      test: [ "CMD", "curl", "-f", "http://localhost:9000/minio/health/live" ]
      interval: 15s
      timeout: 20s
      retries: 5
    deploy:
      placement:
        constraints:
          - node.labels.${STACK_NAME?Variable not set}.minio-data == true
      labels:
        - traefik.enable=true
        - traefik.docker.network=${TRAEFIK_PUBLIC_NETWORK?Variable not set}
        - traefik.constraint-label=${TRAEFIK_PUBLIC_TAG?Variable not set}
        - traefik.http.routers.${STACK_NAME?Variable not set}-minio-http.rule=Host(`minio.${DOMAIN?Variable not set}`)
        - traefik.http.routers.${STACK_NAME?Variable not set}-minio-http.entrypoints=http
        - traefik.http.routers.${STACK_NAME?Variable not set}-minio-http.middlewares=https-redirect,common-security-headers
        - traefik.http.routers.${STACK_NAME?Variable not set}-minio-http.service=${STACK_NAME?Variable not set}-minio
        - traefik.http.routers.${STACK_NAME?Variable not set}-minio-https.rule=Host(`minio.${DOMAIN?Variable not set}`)
        - traefik.http.routers.${STACK_NAME?Variable not set}-minio-https.entrypoints=https
        - traefik.http.routers.${STACK_NAME?Variable not set}-minio-https.tls=true
        - traefik.http.routers.${STACK_NAME?Variable not set}-minio-https.tls.certresolver=le
        - traefik.http.routers.${STACK_NAME?Variable not set}-minio-https.middlewares=common-security-headers
        - traefik.http.routers.${STACK_NAME?Variable not set}-minio-https.service=${STACK_NAME?Variable not set}-minio
        - traefik.http.services.${STACK_NAME?Variable not set}-minio.loadbalancer.server.port=9000
        - traefik.http.routers.${STACK_NAME?Variable not set}-minio-console-http.rule=Host(`minio-console.${DOMAIN?Variable not set}`)
        - traefik.http.routers.${STACK_NAME?Variable not set}-minio-console-http.entrypoints=http
        - traefik.http.routers.${STACK_NAME?Variable not set}-minio-console-http.middlewares=https-redirect,common-security-headers
        - traefik.http.routers.${STACK_NAME?Variable not set}-minio-console-http.service=${STACK_NAME?Variable not set}-minio-console
        - traefik.http.routers.${STACK_NAME?Variable not set}-minio-console-https.rule=Host(`minio-console.${DOMAIN?Variable not set}`)
        - traefik.http.routers.${STACK_NAME?Variable not set}-minio-console-https.entrypoints=https
        - traefik.http.routers.${STACK_NAME?Variable not set}-minio-console-https.tls=true
        - traefik.http.routers.${STACK_NAME?Variable not set}-minio-console-https.tls.certresolver=le
        - traefik.http.routers.${STACK_NAME?Variable not set}-minio-console-https.middlewares=common-security-headers
        - traefik.http.routers.${STACK_NAME?Variable not set}-minio-console-https.service=${STACK_NAME?Variable not set}-minio-console
        - traefik.http.services.${STACK_NAME?Variable not set}-minio-console.loadbalancer.server.port=9001
        - prometheus.port=9000
        - prometheus.path=/minio/v2/metrics/cluster

  general-memcached:
    image: memcached:1.6.19
    networks:
      default:
      prometheus:
    command: memcached --memory-limit=1024 --max-item-size=5m --conn-limit=1024

  loki-read:
    <<: *loki_defaults
    environment:
      - TARGET=read

  loki-write:
    <<: *loki_defaults
    environment:
      - TARGET=write

  loki-backend:
    <<: *loki_defaults
    environment:
      - TARGET=backend

  loki-gateway:
    image: bitnami/nginx:${NGINX_VERSION?Variable not set}
    depends_on:
      - loki-read
      - loki-write
      - loki-backend
    entrypoint:
      - sh
      - -euc
      - |
        cat <<EOF > /opt/bitnami/nginx/conf/server_blocks/default.conf
        proxy_http_version    1.1;
        resolver 127.0.0.11 valid=10s ipv6=off;
        resolver_timeout      10s;
        upstream read {
          server loki-read:3100;
        }
        upstream write {
          server loki-write:3100;
        }
        upstream backend {
          server loki-backend:3100;
        }
        server {
          listen  8080;
          location = / {
            return 200 'OK';
            auth_basic off;
          }
          # Distributor
          location = /api/prom/push {
            proxy_pass       http://write\$$request_uri;
          }
          location = /loki/api/v1/push {
            proxy_pass       http://write\$$request_uri;
          }
          location = /distributor/ring {
            proxy_pass       http://write\$$request_uri;
          }

          # Ingester
          location = /flush {
            proxy_pass       http://write\$$request_uri;
          }
          location ^~ /ingester/ {
            proxy_pass       http://write\$$request_uri;
          }
          location = /ingester {
            internal;        # to suppress 301
          }

          # Ring
          location = /ring {
            proxy_pass       http://write\$$request_uri;
          }

          # MemberListKV
          location = /memberlist {
            proxy_pass       http://write\$$request_uri;
          }

          # Ruler
          location = /ruler/ring {
            proxy_pass       http://backend\$$request_uri;
          }
          location = /api/prom/rules {
            proxy_pass       http://backend\$$request_uri;
          }
          location ^~ /api/prom/rules/ {
            proxy_pass       http://backend\$$request_uri;
          }
          location = /loki/api/v1/rules {
            proxy_pass       http://backend\$$request_uri;
          }
          location ^~ /loki/api/v1/rules/ {
            proxy_pass       http://backend\$$request_uri;
          }
          location = /prometheus/api/v1/alerts {
            proxy_pass       http://backend\$$request_uri;
          }
          location = /prometheus/api/v1/rules {
            proxy_pass       http://backend\$$request_uri;
          }

          # Compactor
          location = /compactor/ring {
            proxy_pass       http://backend\$$request_uri;
          }
          location = /loki/api/v1/delete {
            proxy_pass       http://backend\$$request_uri;
          }
          location = /loki/api/v1/cache/generation_numbers {
            proxy_pass       http://backend\$$request_uri;
          }

          # IndexGateway
          location = /indexgateway/ring {
            proxy_pass       http://backend\$$request_uri;
          }

          # QueryScheduler
          location = /scheduler/ring {
            proxy_pass       http://backend\$$request_uri;
          }

          # QueryFrontend, Querier
          location = /api/prom/tail {
            proxy_pass       http://read\$$request_uri;
            proxy_set_header Upgrade \$$http_upgrade;
            proxy_set_header Connection "upgrade";
          }
          location = /loki/api/v1/tail {
            proxy_pass       http://read\$$request_uri;
            proxy_set_header Upgrade \$$http_upgrade;
            proxy_set_header Connection "upgrade";
          }
          location ^~ /api/prom/ {
            proxy_pass       http://read\$$request_uri;
          }
          location = /api/prom {
            internal;        # to suppress 301
          }
          location ^~ /loki/api/v1/ {
            proxy_pass       http://read\$$request_uri;
          }
          location = /loki/api/v1 {
            internal;        # to suppress 301
          }
        }
        EOF
        exec /opt/bitnami/scripts/nginx/entrypoint.sh /opt/bitnami/scripts/nginx/run.sh

  promtail:
    image: grafana/promtail:${LOKI_VERSION?Variable not set}
    depends_on:
      - loki-gateway
    networks:
      default:
      traefik-public:
      prometheus:
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock:ro
      - /var/lib/docker/containers:/var/lib/docker/containers:ro
      - /var/log:/var/log:ro
      - promtail-data:/run/promtail
    environment:
      - HOSTNAME={{.Node.Hostname}}
    entrypoint:
      - sh
      - -euc
      - |
        cat <<EOF > /etc/promtail/config.yml
        positions:
          filename: /run/promtail/positions.yaml
        clients:
          - url: http://loki-gateway:8080/loki/api/v1/push
            # tenant_id: fake
        scrape_configs:
          - job_name: docker_stack_scrape
            docker_sd_configs:
              - host: unix:///var/run/docker.sock
                refresh_interval: 5s
            relabel_configs:
              # Only keep containers in a stack.
              - source_labels: [__meta_docker_container_label_com_docker_stack_namespace]
                regex: '.+'
                action: keep
              - source_labels: [__meta_docker_container_label_com_docker_stack_namespace]
                target_label: namespace
              - source_labels: [__meta_docker_container_label_com_docker_swarm_service_name]
                target_label: service
              - source_labels: [__meta_docker_container_label_com_docker_swarm_task_id]
                target_label: instance
              - source_labels: ['__meta_docker_container_log_stream']
                target_label: 'stream'
            pipeline_stages:
              - json:
                  expressions:
                    level: level
                    timestamp: time
              - timestamp:
                  source: timestamp
                  format: RFC3339Nano
              - labels:
                  level:
        EOF
        exec /usr/bin/promtail -config.file=/etc/promtail/config.yml
    deploy:
      mode: global
      labels:
        - traefik.enable=true
        - traefik.docker.network=${TRAEFIK_PUBLIC_NETWORK?Variable not set}
        - traefik.constraint-label=${TRAEFIK_PUBLIC_TAG?Variable not set}
        - traefik.http.middlewares.${STACK_NAME?Variable not set}-promtail-auth.basicauth.users=${USERNAME?Variable not set}:${HASHED_PASSWORD?Variable not set}
        - traefik.http.routers.${STACK_NAME?Variable not set}-promtail-http.rule=Host(`promtail.${DOMAIN?Variable not set}`)
        - traefik.http.routers.${STACK_NAME?Variable not set}-promtail-http.entrypoints=http
        - traefik.http.routers.${STACK_NAME?Variable not set}-promtail-http.middlewares=https-redirect,common-security-headers
        - traefik.http.routers.${STACK_NAME?Variable not set}-promtail-https.rule=Host(`promtail.${DOMAIN?Variable not set}`)
        - traefik.http.routers.${STACK_NAME?Variable not set}-promtail-https.entrypoints=https
        - traefik.http.routers.${STACK_NAME?Variable not set}-promtail-https.tls=true
        - traefik.http.routers.${STACK_NAME?Variable not set}-promtail-https.tls.certresolver=le
        - traefik.http.routers.${STACK_NAME?Variable not set}-promtail-https.middlewares=common-security-headers,${STACK_NAME?Variable not set}-promtail-auth
        - traefik.http.services.${STACK_NAME?Variable not set}-promtail.loadbalancer.server.port=80

  loki-canary:
    image: grafana/loki-canary:${LOKI_VERSION?Variable not set}
    depends_on:
      - promtail
    networks:
      default:
      prometheus:
    entrypoint: sh -euc 'exec /usr/bin/loki-canary -addr=loki-gateway:8080 -labelname=instance -labelvalue=$$INSTANCE'
    environment:
      - INSTANCE={{.Task.ID}}
    deploy:
      mode: global
      labels:
        - prometheus.port=3500

  tempo-distributor:
    <<: *tempo_defaults
    environment:
      - TARGET=distributor
    deploy:
      replicas: 3
      labels:
        - prometheus.port=3100
      resources:
        limits:
          cpus: '0.5'
          memory: 1G
        reservations:
          cpus: '0.1'
          memory: 250M

  tempo-ingester:
    <<: *tempo_defaults
    environment:
      - TARGET=ingester
    deploy:
      replicas: 3
      labels:
        - prometheus.port=3100
      resources:
        limits:
          cpus: '0.5'
          memory: 1G
        reservations:
          cpus: '0.1'
          memory: 250M

  tempo-query-frontend:
    <<: *tempo_defaults
    environment:
      - TARGET=query-frontend

  tempo-querier:
    <<: *tempo_defaults
    environment:
      - TARGET=querier

  tempo-compactor:
    <<: *tempo_defaults
    environment:
      - TARGET=compactor

  tempo-metrics-generator:
    <<: *tempo_defaults
    environment:
      - TARGET=metrics-generator

  tempo-gateway:
    image: bitnami/nginx:${NGINX_VERSION?Variable not set}
    networks:
      default:
      prometheus:
    depends_on:
      - tempo-distributor
      - tempo-query-frontend
      - tempo-ingester
      - tempo-compactor
    entrypoint:
      - sh
      - -euc
      - |
        cat <<EOF > /opt/bitnami/nginx/conf/server_blocks/default.conf
        proxy_http_version    1.1;
        resolver 127.0.0.11 valid=10s ipv6=off;
        resolver_timeout      10s;
        upstream otlp_distributor {
          least_conn;
          server tempo-distributor:4317;
        }
        upstream jaeger_distributor {
          server tempo-distributor:14268;
        }
        upstream zipkin_distributor {
          server tempo-distributor:9411;
        }
        upstream otlphttp_distributor {
          server tempo-distributor:4318;
        }
        upstream distributor {
          server tempo-distributor:3100;
        }
        upstream ingester {
          server tempo-ingester:3100;
        }
        upstream compactor {
          server tempo-compactor:3100;
        }
        server {
          listen 4317 http2;
          location / {
            grpc_pass grpc://otlp_distributor;
          }
        }
        server {
          listen             8080;
          location = / {
            return 200 'OK';
            auth_basic off;
          }
          location = /jaeger/api/traces {
            proxy_pass       http://jaeger_distributor/api/traces;
          }
          location = /zipkin/spans {
            proxy_pass       http://zipkin_distributor/spans;
          }
          location = /otlp/v1/traces {
            proxy_pass       http://otlphttp_distributor/v1/traces;
          }
          location ^~ /api {
            proxy_pass       http://tempo-query-frontend:3100\$$request_uri;
          }
          location = /flush {
            proxy_pass       http://ingester\$$request_uri;
          }
          location = /shutdown {
            proxy_pass       http://ingester\$$request_uri;
          }
          location = /ingester/ring {
            proxy_pass       http://distributor\$$request_uri;
          }
          location = /compactor/ring {
            proxy_pass       http://compactor\$$request_uri;
          }
        }
        EOF
        exec /opt/bitnami/scripts/nginx/entrypoint.sh /opt/bitnami/scripts/nginx/run.sh

  otel-collector:
    image: ${DOCKER_OTEL_IMAGE?Variable not set}:${OTEL_VERSION?Variable not set}
    build:
      context: ./otel-collector
      args:
        OTEL_VERSION: ${OTEL_VERSION?Variable not set}
    depends_on:
      - tempo-gateway
    networks:
      default:
      prometheus:
    deploy:
      labels:
        - prometheus.port=8389

  k6-tracing:
    image: ghcr.io/grafana/xk6-client-tracing:v0.0.2
    depends_on:
      - otel-collector
    environment:
      - ENDPOINT=otel-collector:4317

  grafana:
    image: ${DOCKER_GRAFANA_IMAGE?Variable not set}:v${GRAFANA_VERSION?Variable not set}
    depends_on:
      - prometheus
      - promtail
      - loki-gateway
      - tempo-gateway
    build:
      context: ./grafana
      args:
        GRAFANA_VERSION: ${GRAFANA_VERSION?Variable not set}
    networks:
      default:
      traefik-public:
      prometheus:
    environment:
      - GF_SECURITY_ADMIN_USER=${USERNAME?Variable not set}
      - GF_SECURITY_ADMIN_PASSWORD=${PASSWORD?Variable not set}
      - GF_SECURITY_COOKIE_SECURE=true
      - GF_USERS_ALLOW_SIGN_UP=false
      - GF_SERVER_ROOT_URL=https://${DOMAIN?Variable not set}/
      - GF_SERVER_ENABLE_GZIP=true
      - GF_INSTALL_PLUGINS=${GRAFANA_PLUGINS?Variable not set}
      - GF_FEATURE_TOGGLES_ENABLE=${GRAFANA_FEATURES?Variable not set}
    volumes:
      - grafana-data:/var/lib/grafana
    deploy:
      placement:
        constraints:
          - node.labels.${STACK_NAME?Variable not set}.grafana-data == true
      resources:
        limits:
          memory: 2048M
        reservations:
          memory: 512M
      labels:
        - traefik.enable=true
        - traefik.docker.network=${TRAEFIK_PUBLIC_NETWORK?Variable not set}
        - traefik.constraint-label=${TRAEFIK_PUBLIC_TAG?Variable not set}
        - traefik.http.routers.${STACK_NAME?Variable not set}-grafana-http.rule=Host(`${DOMAIN?Variable not set}`) && PathPrefix(`/`)
        - traefik.http.routers.${STACK_NAME?Variable not set}-grafana-http.entrypoints=http
        - traefik.http.routers.${STACK_NAME?Variable not set}-grafana-http.middlewares=https-redirect,common-security-headers
        - traefik.http.routers.${STACK_NAME?Variable not set}-grafana-https.rule=Host(`${DOMAIN?Variable not set}`) && PathPrefix(`/`)
        - traefik.http.routers.${STACK_NAME?Variable not set}-grafana-https.entrypoints=https
        - traefik.http.routers.${STACK_NAME?Variable not set}-grafana-https.tls=true
        - traefik.http.routers.${STACK_NAME?Variable not set}-grafana-https.tls.certresolver=le
        - traefik.http.routers.${STACK_NAME?Variable not set}-grafana-https.middlewares=common-security-headers
        - traefik.http.services.${STACK_NAME?Variable not set}-grafana.loadbalancer.server.port=3000
        - prometheus.port=9090

volumes:
  prometheus-data:
  minio-data:
  loki-read-data:
  loki-write-data:
  promtail-data:
  grafana-data:

networks:
  default:
    name: ${STACK_NAME?Variable not set}_default
    driver: overlay
    attachable: true
    ipam:
      config:
        - subnet: 10.0.3.0/24
  traefik-public:
    name: ${TRAEFIK_PUBLIC_NETWORK?Variable not set}
    external: ${TRAEFIK_PUBLIC_IS_EXTERNAL?Variable not set}
  prometheus:
    name: ${PROMETHEUS_NETWORK?Variable not set}
    external: ${PROMETHEUS_IS_EXTERNAL?Variable not set}
